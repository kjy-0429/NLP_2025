{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0bad285-5973-466b-b9db-bd84a9a82032",
      "metadata": {
        "id": "a0bad285-5973-466b-b9db-bd84a9a82032"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUQsl9vywuB_",
        "outputId": "e46ec993-d5b0-4053-bf3f-9d04eb9131b4"
      },
      "id": "cUQsl9vywuB_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54faa128-a388-46a0-b0fc-8d57790b0d68",
      "metadata": {
        "id": "54faa128-a388-46a0-b0fc-8d57790b0d68"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066c78db-1826-4839-8631-3cc9c8307f27",
      "metadata": {
        "id": "066c78db-1826-4839-8631-3cc9c8307f27"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4649eec-1903-439f-bd9d-7a9bf75af91c",
      "metadata": {
        "id": "e4649eec-1903-439f-bd9d-7a9bf75af91c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a86843-bbfa-4bbd-8e81-97828cf3a062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_meta: (944767, 3)\n",
            "train_A: (647241, 37)\n",
            "train_B: (297526, 31)\n"
          ]
        }
      ],
      "source": [
        "BASE_DIR = \"./data\"\n",
        "\n",
        "train_meta = pd.read_csv(os.path.join(BASE_DIR, \"/content/drive/MyDrive/data/train.csv\"))\n",
        "train_A = pd.read_csv(os.path.join(BASE_DIR, \"/content/drive/MyDrive/data/train/A.csv\"))\n",
        "train_B = pd.read_csv(os.path.join(BASE_DIR, \"/content/drive/MyDrive/data/train/B.csv\"))\n",
        "\n",
        "print(\"train_meta:\", train_meta.shape)\n",
        "print(\"train_A:\", train_A.shape)\n",
        "print(\"train_B:\", train_B.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ae7f99-c123-4ddf-90d3-2859b2eabeb8",
      "metadata": {
        "id": "c5ae7f99-c123-4ddf-90d3-2859b2eabeb8"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcbed49f-f079-47c4-a28a-b1dc6507bf84",
      "metadata": {
        "id": "fcbed49f-f079-47c4-a28a-b1dc6507bf84"
      },
      "outputs": [],
      "source": [
        "def convert_age(val):\n",
        "    if pd.isna(val): return np.nan\n",
        "    try:\n",
        "        base = int(str(val)[:-1])\n",
        "        return base if str(val)[-1] == \"a\" else base + 5\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def split_testdate(val):\n",
        "    try:\n",
        "        v = int(val)\n",
        "        return v // 100, v % 100\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def seq_mean(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").mean() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_std(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").std() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_rate(series, target=\"1\"):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: str(x).split(\",\").count(target) / len(x.split(\",\")) if x else np.nan\n",
        "    )\n",
        "\n",
        "def masked_mean_from_csv_series(cond_series, val_series, mask_val):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "\n",
        "    mask = (cond_arr == mask_val)\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts==0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\n",
        "def masked_mean_in_set_series(cond_series, val_series, mask_set):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "\n",
        "    mask = np.isin(cond_arr, list(mask_set))\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts == 0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5425d5-97e0-4f61-937b-808e29e5762d",
      "metadata": {
        "id": "cc5425d5-97e0-4f61-937b-808e29e5762d"
      },
      "source": [
        "## 1차 Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4bdb55-d79d-4958-a236-492cfd0137cb",
      "metadata": {
        "id": "7e4bdb55-d79d-4958-a236-492cfd0137cb"
      },
      "outputs": [],
      "source": [
        "def preprocess_A(train_A):\n",
        "    df = train_A.copy()\n",
        "\n",
        "    # ---- Age, TestDate 파생 ----\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    # ---- A1 ----\n",
        "    print(\"Step 2: A1 feature 생성...\")\n",
        "    feats[\"A1_resp_rate\"] = seq_rate(df[\"A1-3\"], \"1\")\n",
        "    feats[\"A1_rt_mean\"]   = seq_mean(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_std\"]    = seq_std(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_left\"]   = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_right\"]  = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 2)\n",
        "    feats[\"A1_rt_side_diff\"] = feats[\"A1_rt_left\"] - feats[\"A1_rt_right\"]\n",
        "    feats[\"A1_rt_slow\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_fast\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 3)\n",
        "    feats[\"A1_rt_speed_diff\"] = feats[\"A1_rt_slow\"] - feats[\"A1_rt_fast\"]\n",
        "\n",
        "    # ---- A2 ----\n",
        "    print(\"Step 3: A2 feature 생성...\")\n",
        "    feats[\"A2_resp_rate\"] = seq_rate(df[\"A2-3\"], \"1\")\n",
        "    feats[\"A2_rt_mean\"]   = seq_mean(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_std\"]    = seq_std(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_cond1_diff\"] = masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 3)\n",
        "    feats[\"A2_rt_cond2_diff\"] = masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 3)\n",
        "\n",
        "    # ---- A3 ----\n",
        "    print(\"Step 4: A3 feature 생성...\")\n",
        "    s = df[\"A3-5\"].fillna(\"\")\n",
        "    total   = s.apply(lambda x: len(x.split(\",\")) if x else 0)\n",
        "    valid   = s.apply(lambda x: sum(v in {\"1\",\"2\"} for v in x.split(\",\")) if x else 0)\n",
        "    invalid = s.apply(lambda x: sum(v in {\"3\",\"4\"} for v in x.split(\",\")) if x else 0)\n",
        "    correct = s.apply(lambda x: sum(v in {\"1\",\"3\"} for v in x.split(\",\")) if x else 0)\n",
        "    feats[\"A3_valid_ratio\"]   = (valid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_invalid_ratio\"] = (invalid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_correct_ratio\"] = (correct / total).replace([np.inf,-np.inf], np.nan)\n",
        "\n",
        "    feats[\"A3_resp2_rate\"] = seq_rate(df[\"A3-6\"], \"1\")\n",
        "    feats[\"A3_rt_mean\"]    = seq_mean(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_std\"]     = seq_std(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_size_diff\"] = masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 2)\n",
        "    feats[\"A3_rt_side_diff\"] = masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 2)\n",
        "\n",
        "    # ---- A4 ----\n",
        "    print(\"Step 5: A4 feature 생성...\")\n",
        "    feats[\"A4_acc_rate\"]   = seq_rate(df[\"A4-3\"], \"1\")\n",
        "    feats[\"A4_resp2_rate\"] = seq_rate(df[\"A4-4\"], \"1\")\n",
        "    feats[\"A4_rt_mean\"]    = seq_mean(df[\"A4-5\"])\n",
        "    feats[\"A4_rt_std\"]     = seq_std(df[\"A4-5\"])\n",
        "    feats[\"A4_stroop_diff\"] = masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 2) - \\\n",
        "                              masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 1)\n",
        "    feats[\"A4_rt_color_diff\"] = masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 2)\n",
        "\n",
        "    # ---- A5 ----\n",
        "    print(\"Step 6: A5 feature 생성...\")\n",
        "    feats[\"A5_acc_rate\"]   = seq_rate(df[\"A5-2\"], \"1\")\n",
        "    feats[\"A5_resp2_rate\"] = seq_rate(df[\"A5-3\"], \"1\")\n",
        "    feats[\"A5_acc_nonchange\"] = masked_mean_from_csv_series(df[\"A5-1\"], df[\"A5-2\"], 1)\n",
        "    feats[\"A5_acc_change\"]    = masked_mean_in_set_series(df[\"A5-1\"], df[\"A5-2\"], {2,3,4})\n",
        "\n",
        "    # ---- Drop ----\n",
        "    print(\"Step 7: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"A1-1\",\"A1-2\",\"A1-3\",\"A1-4\",\n",
        "        \"A2-1\",\"A2-2\",\"A2-3\",\"A2-4\",\n",
        "        \"A3-1\",\"A3-2\",\"A3-3\",\"A3-4\",\"A3-5\",\"A3-6\",\"A3-7\",\n",
        "        \"A4-1\",\"A4-2\",\"A4-3\",\"A4-4\",\"A4-5\",\n",
        "        \"A5-1\",\"A5-2\",\"A5-3\"\n",
        "    ]\n",
        "    print(\"A 검사 데이터 전처리 완료\")\n",
        "    return pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b781b03-8be4-4204-aca8-a49f4d8768b7",
      "metadata": {
        "id": "0b781b03-8be4-4204-aca8-a49f4d8768b7"
      },
      "outputs": [],
      "source": [
        "def preprocess_B(train_B):\n",
        "    df = train_B.copy()\n",
        "\n",
        "    # ---- Age, TestDate ----\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    # ---- B1 ----\n",
        "    print(\"Step 2: B1 feature 생성...\")\n",
        "    feats[\"B1_acc_task1\"] = seq_rate(df[\"B1-1\"], \"1\")\n",
        "    feats[\"B1_rt_mean\"]   = seq_mean(df[\"B1-2\"])\n",
        "    feats[\"B1_rt_std\"]    = seq_std(df[\"B1-2\"])\n",
        "    feats[\"B1_acc_task2\"] = seq_rate(df[\"B1-3\"], \"1\")\n",
        "\n",
        "    # ---- B2 ----\n",
        "    print(\"Step 3: B2 feature 생성...\")\n",
        "    feats[\"B2_acc_task1\"] = seq_rate(df[\"B2-1\"], \"1\")\n",
        "    feats[\"B2_rt_mean\"]   = seq_mean(df[\"B2-2\"])\n",
        "    feats[\"B2_rt_std\"]    = seq_std(df[\"B2-2\"])\n",
        "    feats[\"B2_acc_task2\"] = seq_rate(df[\"B2-3\"], \"1\")\n",
        "\n",
        "    # ---- B3 ----\n",
        "    print(\"Step 4: B3 feature 생성...\")\n",
        "    feats[\"B3_acc_rate\"] = seq_rate(df[\"B3-1\"], \"1\")\n",
        "    feats[\"B3_rt_mean\"]  = seq_mean(df[\"B3-2\"])\n",
        "    feats[\"B3_rt_std\"]   = seq_std(df[\"B3-2\"])\n",
        "\n",
        "    # ---- B4 ----\n",
        "    print(\"Step 5: B4 feature 생성...\")\n",
        "    feats[\"B4_acc_rate\"] = seq_rate(df[\"B4-1\"], \"1\")\n",
        "    feats[\"B4_rt_mean\"]  = seq_mean(df[\"B4-2\"])\n",
        "    feats[\"B4_rt_std\"]   = seq_std(df[\"B4-2\"])\n",
        "\n",
        "    # ---- B5 ----\n",
        "    print(\"Step 6: B5 feature 생성...\")\n",
        "    feats[\"B5_acc_rate\"] = seq_rate(df[\"B5-1\"], \"1\")\n",
        "    feats[\"B5_rt_mean\"]  = seq_mean(df[\"B5-2\"])\n",
        "    feats[\"B5_rt_std\"]   = seq_std(df[\"B5-2\"])\n",
        "\n",
        "    # ---- B6~B8 ----\n",
        "    print(\"Step 7: B6~B8 feature 생성...\")\n",
        "    feats[\"B6_acc_rate\"] = seq_rate(df[\"B6\"], \"1\")\n",
        "    feats[\"B7_acc_rate\"] = seq_rate(df[\"B7\"], \"1\")\n",
        "    feats[\"B8_acc_rate\"] = seq_rate(df[\"B8\"], \"1\")\n",
        "\n",
        "    # ---- Drop ----\n",
        "    print(\"Step 8: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"B1-1\",\"B1-2\",\"B1-3\",\n",
        "        \"B2-1\",\"B2-2\",\"B2-3\",\n",
        "        \"B3-1\",\"B3-2\",\n",
        "        \"B4-1\",\"B4-2\",\n",
        "        \"B5-1\",\"B5-2\",\n",
        "        \"B6\",\"B7\",\"B8\"\n",
        "    ]\n",
        "\n",
        "    print(\"B 검사 데이터 전처리 완료\")\n",
        "    return pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf8303c-9c54-4465-9c91-c1ef18d5d08b",
      "metadata": {
        "id": "fcf8303c-9c54-4465-9c91-c1ef18d5d08b",
        "outputId": "aec3ad5e-7b2d-4951-a8bf-2038a9358d6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: A1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 647241/647241 [00:01<00:00, 509350.29it/s]\n",
            "100%|██████████| 647241/647241 [00:09<00:00, 71518.04it/s]\n",
            "100%|██████████| 647241/647241 [00:21<00:00, 30443.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: A2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 647241/647241 [00:01<00:00, 514028.14it/s]\n",
            "100%|██████████| 647241/647241 [00:08<00:00, 73005.53it/s]\n",
            "100%|██████████| 647241/647241 [00:20<00:00, 31340.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: A3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 647241/647241 [00:01<00:00, 346210.85it/s]\n",
            "100%|██████████| 647241/647241 [00:09<00:00, 67190.29it/s]\n",
            "100%|██████████| 647241/647241 [00:23<00:00, 27881.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: A4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 647241/647241 [00:02<00:00, 241461.92it/s]\n",
            "100%|██████████| 647241/647241 [00:04<00:00, 142793.37it/s]\n",
            "100%|██████████| 647241/647241 [00:18<00:00, 35730.46it/s]\n",
            "100%|██████████| 647241/647241 [00:31<00:00, 20320.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: A5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 647241/647241 [00:01<00:00, 406341.05it/s]\n",
            "100%|██████████| 647241/647241 [00:02<00:00, 277595.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: 시퀀스 컬럼 drop & concat...\n",
            "A 검사 데이터 전처리 완료\n",
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: B1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:00<00:00, 635046.75it/s]\n",
            "100%|██████████| 297526/297526 [00:04<00:00, 61554.51it/s]\n",
            "100%|██████████| 297526/297526 [00:08<00:00, 34081.40it/s]\n",
            "100%|██████████| 297526/297526 [00:00<00:00, 540113.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: B2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:00<00:00, 427678.04it/s]\n",
            "100%|██████████| 297526/297526 [00:04<00:00, 63434.66it/s]\n",
            "100%|██████████| 297526/297526 [00:09<00:00, 32963.78it/s]\n",
            "100%|██████████| 297526/297526 [00:00<00:00, 306314.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: B3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:00<00:00, 378869.67it/s]\n",
            "100%|██████████| 297526/297526 [00:04<00:00, 74360.15it/s]\n",
            "100%|██████████| 297526/297526 [00:09<00:00, 32293.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: B4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:02<00:00, 136113.74it/s]\n",
            "100%|██████████| 297526/297526 [00:05<00:00, 52070.56it/s]\n",
            "100%|██████████| 297526/297526 [00:13<00:00, 22611.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: B5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:00<00:00, 601319.95it/s]\n",
            "100%|██████████| 297526/297526 [00:03<00:00, 87902.84it/s]\n",
            "100%|██████████| 297526/297526 [00:10<00:00, 28204.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: B6~B8 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 297526/297526 [00:00<00:00, 648441.08it/s]\n",
            "100%|██████████| 297526/297526 [00:00<00:00, 586408.07it/s]\n",
            "100%|██████████| 297526/297526 [00:00<00:00, 741649.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 8: 시퀀스 컬럼 drop & concat...\n",
            "B 검사 데이터 전처리 완료\n",
            "A: (647241, 49) B: (297526, 39)\n"
          ]
        }
      ],
      "source": [
        "train_A_features = preprocess_A(train_A)\n",
        "train_B_features = preprocess_B(train_B)\n",
        "\n",
        "print(\"A:\", train_A_features.shape, \"B:\", train_B_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6da9de9-9ee5-4f62-8460-c8088b9aa8b1",
      "metadata": {
        "id": "a6da9de9-9ee5-4f62-8460-c8088b9aa8b1"
      },
      "source": [
        "## 2차 Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c81a810-2334-44d0-a626-fc7c78223cb4",
      "metadata": {
        "id": "1c81a810-2334-44d0-a626-fc7c78223cb4"
      },
      "outputs": [],
      "source": [
        "# -------- 공통 유틸 --------\n",
        "def _has(df, cols):  # 필요한 컬럼이 모두 있는지\n",
        "    return all(c in df.columns for c in cols)\n",
        "\n",
        "def _safe_div(a, b, eps=1e-6):\n",
        "    return a / (b + eps)\n",
        "\n",
        "# -------- A 파생 --------\n",
        "def add_features_A(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy()\n",
        "    eps = 1e-6\n",
        "\n",
        "    # 0) Year-Month 단일축\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    # 1) 속도-정확도 트레이드오프\n",
        "    if _has(feats, [\"A1_rt_mean\",\"A1_resp_rate\"]):\n",
        "        feats[\"A1_speed_acc_tradeoff\"] = _safe_div(feats[\"A1_rt_mean\"], feats[\"A1_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A2_rt_mean\",\"A2_resp_rate\"]):\n",
        "        feats[\"A2_speed_acc_tradeoff\"] = _safe_div(feats[\"A2_rt_mean\"], feats[\"A2_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A4_rt_mean\",\"A4_acc_rate\"]):\n",
        "        feats[\"A4_speed_acc_tradeoff\"] = _safe_div(feats[\"A4_rt_mean\"], feats[\"A4_acc_rate\"], eps)\n",
        "\n",
        "    # 2) RT 변동계수(CV)\n",
        "    for k in [\"A1\",\"A2\",\"A3\",\"A4\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    # 3) 조건 차이 절댓값(편향 크기)\n",
        "    for name, base in [\n",
        "        (\"A1_rt_side_gap_abs\",  \"A1_rt_side_diff\"),\n",
        "        (\"A1_rt_speed_gap_abs\", \"A1_rt_speed_diff\"),\n",
        "        (\"A2_rt_cond1_gap_abs\", \"A2_rt_cond1_diff\"),\n",
        "        (\"A2_rt_cond2_gap_abs\", \"A2_rt_cond2_diff\"),\n",
        "        (\"A4_stroop_gap_abs\",   \"A4_stroop_diff\"),\n",
        "        (\"A4_color_gap_abs\",    \"A4_rt_color_diff\"),\n",
        "    ]:\n",
        "        if base in feats.columns:\n",
        "            feats[name] = feats[base].abs()\n",
        "\n",
        "    # 4) 정확도 패턴 심화\n",
        "    if _has(feats, [\"A3_valid_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_valid_invalid_gap\"] = feats[\"A3_valid_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A3_correct_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_correct_invalid_gap\"] = feats[\"A3_correct_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A5_acc_change\",\"A5_acc_nonchange\"]):\n",
        "        feats[\"A5_change_nonchange_gap\"] = feats[\"A5_acc_change\"] - feats[\"A5_acc_nonchange\"]\n",
        "\n",
        "    # 5) 간단 메타 리스크 스코어(휴리스틱)\n",
        "    parts = []\n",
        "    if \"A4_stroop_gap_abs\" in feats: parts.append(0.30 * feats[\"A4_stroop_gap_abs\"].fillna(0))\n",
        "    if \"A4_acc_rate\" in feats:       parts.append(0.20 * (1 - feats[\"A4_acc_rate\"].fillna(0)))\n",
        "    if \"A3_valid_invalid_gap\" in feats:\n",
        "        parts.append(0.20 * feats[\"A3_valid_invalid_gap\"].fillna(0).abs())\n",
        "    if \"A1_rt_cv\" in feats: parts.append(0.20 * feats[\"A1_rt_cv\"].fillna(0))\n",
        "    if \"A2_rt_cv\" in feats: parts.append(0.10 * feats[\"A2_rt_cv\"].fillna(0))\n",
        "    if parts:\n",
        "        feats[\"RiskScore\"] = sum(parts)\n",
        "\n",
        "    # NaN/inf 정리\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats\n",
        "\n",
        "# -------- B 파생 --------\n",
        "def add_features_B(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy()\n",
        "    eps = 1e-6\n",
        "\n",
        "    # 0) Year-Month 단일축\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    # 1) 속도-정확도 트레이드오프 (B1~B5)\n",
        "    for k, acc_col, rt_col in [\n",
        "        (\"B1\", \"B1_acc_task1\", \"B1_rt_mean\"),\n",
        "        (\"B2\", \"B2_acc_task1\", \"B2_rt_mean\"),\n",
        "        (\"B3\", \"B3_acc_rate\",  \"B3_rt_mean\"),\n",
        "        (\"B4\", \"B4_acc_rate\",  \"B4_rt_mean\"),\n",
        "        (\"B5\", \"B5_acc_rate\",  \"B5_rt_mean\"),\n",
        "    ]:\n",
        "        if _has(feats, [rt_col, acc_col]):\n",
        "            feats[f\"{k}_speed_acc_tradeoff\"] = _safe_div(feats[rt_col], feats[acc_col], eps)\n",
        "\n",
        "    # 2) RT 변동계수(CV)\n",
        "    for k in [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    # 3) 간단 메타 리스크 스코어(휴리스틱)\n",
        "    parts = []\n",
        "    for k in [\"B4\",\"B5\"]:  # 주의집중/스트룹 유사 과제 가중\n",
        "        if _has(feats, [f\"{k}_rt_cv\"]):\n",
        "            parts.append(0.25 * feats[f\"{k}_rt_cv\"].fillna(0))\n",
        "    for k in [\"B3\",\"B4\",\"B5\"]:\n",
        "        acc = f\"{k}_acc_rate\" if k != \"B1\" and k != \"B2\" else None\n",
        "        if k in [\"B1\",\"B2\"]:\n",
        "            acc = f\"{k}_acc_task1\"\n",
        "        if acc in feats:\n",
        "            parts.append(0.25 * (1 - feats[acc].fillna(0)))\n",
        "    for k in [\"B1\",\"B2\"]:\n",
        "        tcol = f\"{k}_speed_acc_tradeoff\"\n",
        "        if tcol in feats:\n",
        "            parts.append(0.25 * feats[tcol].fillna(0))\n",
        "    if parts:\n",
        "        feats[\"RiskScore_B\"] = sum(parts)\n",
        "\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8565a767-5c06-40aa-b86c-79aa7fcb6adf",
      "metadata": {
        "id": "8565a767-5c06-40aa-b86c-79aa7fcb6adf",
        "outputId": "ed8b9040-5e7a-427f-d7f4-2871f81ee273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A+feat: (647241, 67) B+feat: (297526, 51)\n"
          ]
        }
      ],
      "source": [
        "train_A_features = add_features_A(train_A_features)\n",
        "train_B_features = add_features_B(train_B_features)\n",
        "\n",
        "print(\"A+feat:\", train_A_features.shape, \"B+feat:\", train_B_features.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39dde68-237c-4260-900c-964943d7f45f",
      "metadata": {
        "id": "c39dde68-237c-4260-900c-964943d7f45f"
      },
      "source": [
        "## Train / Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18c2e2a5-334c-4f74-acc3-f4bd0033e0b4",
      "metadata": {
        "id": "18c2e2a5-334c-4f74-acc3-f4bd0033e0b4"
      },
      "outputs": [],
      "source": [
        "meta_A = train_meta[train_meta[\"Test\"]==\"A\"].reset_index(drop=True)\n",
        "meta_B = train_meta[train_meta[\"Test\"]==\"B\"].reset_index(drop=True)\n",
        "\n",
        "X_A, y_A = train_A_features.drop(columns=[\"Test_id\",\"Test\",\"PrimaryKey\",\"Age\",\"TestDate\"]), meta_A[\"Label\"].values\n",
        "X_B, y_B = train_B_features.drop(columns=[\"Test_id\",\"Test\",\"PrimaryKey\",\"Age\",\"TestDate\"]), meta_B[\"Label\"].values\n",
        "\n",
        "X_train_A, X_val_A, y_train_A, y_val_A = train_test_split(X_A, y_A, test_size=0.2, stratify=y_A, random_state=42)\n",
        "X_train_B, X_val_B, y_train_B, y_val_B = train_test_split(X_B, y_B, test_size=0.2, stratify=y_B, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f3c364f-5940-45cb-ad38-5e49128cdf54",
      "metadata": {
        "id": "3f3c364f-5940-45cb-ad38-5e49128cdf54"
      },
      "source": [
        "## Model Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "265304e9-9bc9-4118-a604-68a93e052eea",
      "metadata": {
        "id": "265304e9-9bc9-4118-a604-68a93e052eea"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(X_train, y_train, X_val, y_val, group_label):\n",
        "    model = lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        metric=\"auc\",\n",
        "        n_estimators=3000,\n",
        "        learning_rate=0.05,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric=\"auc\",\n",
        "        callbacks=[lgb.early_stopping(200), lgb.log_evaluation(100)]\n",
        "    )\n",
        "\n",
        "    val_pred = model.predict_proba(X_val)[:,1]\n",
        "    auc = roc_auc_score(y_val, val_pred)\n",
        "    print(f\"[{group_label}] Validation AUC: {auc:.4f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4666f4f6-c602-45f8-bd47-39cca9f03bdb",
      "metadata": {
        "id": "4666f4f6-c602-45f8-bd47-39cca9f03bdb",
        "outputId": "0422f4d7-9ac6-41d3-b248-f9aa9ff7f313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 11754, number of negative: 506038\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.534830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 9626\n",
            "[LightGBM] [Info] Number of data points in the train set: 517792, number of used features: 59\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.022700 -> initscore=-3.762418\n",
            "[LightGBM] [Info] Start training from score -3.762418\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's auc: 0.504672\n",
            "[200]\tvalid_0's auc: 0.508239\n",
            "[300]\tvalid_0's auc: 0.508657\n",
            "[400]\tvalid_0's auc: 0.507633\n",
            "Early stopping, best iteration is:\n",
            "[254]\tvalid_0's auc: 0.510804\n",
            "[A] Validation AUC: 0.5108\n",
            "[LightGBM] [Info] Number of positive: 10072, number of negative: 227948\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043428 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6017\n",
            "[LightGBM] [Info] Number of data points in the train set: 238020, number of used features: 46\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.042316 -> initscore=-3.119358\n",
            "[LightGBM] [Info] Start training from score -3.119358\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's auc: 0.492003\n",
            "[200]\tvalid_0's auc: 0.490617\n",
            "Early stopping, best iteration is:\n",
            "[7]\tvalid_0's auc: 0.499922\n",
            "[B] Validation AUC: 0.4999\n"
          ]
        }
      ],
      "source": [
        "model_A = train_and_eval(X_train_A, y_train_A, X_val_A, y_val_A, \"A\")\n",
        "model_B = train_and_eval(X_train_B, y_train_B, X_val_B, y_val_B, \"B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f1c1b9a-172a-458b-b465-48de7b4cfdb8",
      "metadata": {
        "id": "2f1c1b9a-172a-458b-b465-48de7b4cfdb8"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c2e7f7-5c7c-450c-80d2-be2f0333ec13",
      "metadata": {
        "id": "43c2e7f7-5c7c-450c-80d2-be2f0333ec13",
        "outputId": "947f39c0-73b4-4b87-9e9f-4b3b706c7d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 저장 완료: ./model/lgbm_A.pkl, ./model/lgbm_B.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "# 모델 저장 경로\n",
        "os.makedirs(\"./model\", exist_ok=True)\n",
        "\n",
        "joblib.dump(model_A, \"./model/lgbm_A.pkl\")\n",
        "joblib.dump(model_B, \"./model/lgbm_B.pkl\")\n",
        "\n",
        "print(\"모델 저장 완료: ./model/lgbm_A.pkl, ./model/lgbm_B.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model inference"
      ],
      "metadata": {
        "id": "EHkXPqWp8QL6"
      },
      "id": "EHkXPqWp8QL6"
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 때 사용한 전처리 유틸 (그대로)\n",
        "tqdm.pandas()\n",
        "\n",
        "def convert_age(val):\n",
        "    if pd.isna(val): return np.nan\n",
        "    try:\n",
        "        base = int(str(val)[:-1])\n",
        "        return base if str(val)[-1] == \"a\" else base + 5\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def split_testdate(val):\n",
        "    try:\n",
        "        v = int(val)\n",
        "        return v // 100, v % 100\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def seq_mean(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").mean() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_std(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").std() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_rate(series, target=\"1\"):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: str(x).split(\",\").count(target) / len(x.split(\",\")) if x else np.nan\n",
        "    )\n",
        "\n",
        "def masked_mean_from_csv_series(cond_series, val_series, mask_val):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = (cond_arr == mask_val)\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts==0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\n",
        "def masked_mean_in_set_series(cond_series, val_series, mask_set):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = np.isin(cond_arr, list(mask_set))\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts == 0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n"
      ],
      "metadata": {
        "id": "-Hv3Jaro8Prn"
      },
      "id": "-Hv3Jaro8Prn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 때 사용한 A/B 검사 전처리 (그대로)\n",
        "def preprocess_A(train_A):\n",
        "    df = train_A.copy()\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    print(\"Step 2: A1 feature 생성...\")\n",
        "    feats[\"A1_resp_rate\"] = seq_rate(df[\"A1-3\"], \"1\")\n",
        "    feats[\"A1_rt_mean\"]   = seq_mean(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_std\"]    = seq_std(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_left\"]   = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_right\"]  = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 2)\n",
        "    feats[\"A1_rt_side_diff\"] = feats[\"A1_rt_left\"] - feats[\"A1_rt_right\"]\n",
        "    feats[\"A1_rt_slow\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_fast\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 3)\n",
        "    feats[\"A1_rt_speed_diff\"] = feats[\"A1_rt_slow\"] - feats[\"A1_rt_fast\"]\n",
        "\n",
        "    print(\"Step 3: A2 feature 생성...\")\n",
        "    feats[\"A2_resp_rate\"] = seq_rate(df[\"A2-3\"], \"1\")\n",
        "    feats[\"A2_rt_mean\"]   = seq_mean(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_std\"]    = seq_std(df[\"A2-4\"])\n",
        "    feats[\"A2_rt_cond1_diff\"] = masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-1\"], df[\"A2-4\"], 3)\n",
        "    feats[\"A2_rt_cond2_diff\"] = masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A2-2\"], df[\"A2-4\"], 3)\n",
        "\n",
        "    print(\"Step 4: A3 feature 생성...\")\n",
        "    s = df[\"A3-5\"].fillna(\"\")\n",
        "    total   = s.apply(lambda x: len(x.split(\",\")) if x else 0)\n",
        "    valid   = s.apply(lambda x: sum(v in {\"1\",\"2\"} for v in x.split(\",\")) if x else 0)\n",
        "    invalid = s.apply(lambda x: sum(v in {\"3\",\"4\"} for v in x.split(\",\")) if x else 0)\n",
        "    correct = s.apply(lambda x: sum(v in {\"1\",\"3\"} for v in x.split(\",\")) if x else 0)\n",
        "    feats[\"A3_valid_ratio\"]   = (valid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_invalid_ratio\"] = (invalid / total).replace([np.inf,-np.inf], np.nan)\n",
        "    feats[\"A3_correct_ratio\"] = (correct / total).replace([np.inf,-np.inf], np.nan)\n",
        "\n",
        "    feats[\"A3_resp2_rate\"] = seq_rate(df[\"A3-6\"], \"1\")\n",
        "    feats[\"A3_rt_mean\"]    = seq_mean(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_std\"]     = seq_std(df[\"A3-7\"])\n",
        "    feats[\"A3_rt_size_diff\"] = masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-1\"], df[\"A3-7\"], 2)\n",
        "    feats[\"A3_rt_side_diff\"] = masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 1) - \\\n",
        "                               masked_mean_from_csv_series(df[\"A3-3\"], df[\"A3-7\"], 2)\n",
        "\n",
        "    print(\"Step 5: A4 feature 생성...\")\n",
        "    feats[\"A4_acc_rate\"]   = seq_rate(df[\"A4-3\"], \"1\")\n",
        "    feats[\"A4_resp2_rate\"] = seq_rate(df[\"A4-4\"], \"1\")\n",
        "    feats[\"A4_rt_mean\"]    = seq_mean(df[\"A4-5\"])\n",
        "    feats[\"A4_rt_std\"]     = seq_std(df[\"A4-5\"])\n",
        "    feats[\"A4_stroop_diff\"] = masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 2) - \\\n",
        "                              masked_mean_from_csv_series(df[\"A4-1\"], df[\"A4-5\"], 1)\n",
        "    feats[\"A4_rt_color_diff\"] = masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 1) - \\\n",
        "                                masked_mean_from_csv_series(df[\"A4-2\"], df[\"A4-5\"], 2)\n",
        "\n",
        "    print(\"Step 6: A5 feature 생성...\")\n",
        "    feats[\"A5_acc_rate\"]   = seq_rate(df[\"A5-2\"], \"1\")\n",
        "    feats[\"A5_resp2_rate\"] = seq_rate(df[\"A5-3\"], \"1\")\n",
        "    feats[\"A5_acc_nonchange\"] = masked_mean_from_csv_series(df[\"A5-1\"], df[\"A5-2\"], 1)\n",
        "    feats[\"A5_acc_change\"]    = masked_mean_in_set_series(df[\"A5-1\"], df[\"A5-2\"], {2,3,4})\n",
        "\n",
        "    print(\"Step 7: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"A1-1\",\"A1-2\",\"A1-3\",\"A1-4\",\n",
        "        \"A2-1\",\"A2-2\",\"A2-3\",\"A2-4\",\n",
        "        \"A3-1\",\"A3-2\",\"A3-3\",\"A3-4\",\"A3-5\",\"A3-6\",\"A3-7\",\n",
        "        \"A4-1\",\"A4-2\",\"A4-3\",\"A4-4\",\"A4-5\",\n",
        "        \"A5-1\",\"A5-2\",\"A5-3\"\n",
        "    ]\n",
        "    print(\"A 검사 데이터 전처리 완료\")\n",
        "    out = pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)\n",
        "    out.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
        "    return out\n",
        "\n",
        "def preprocess_B(train_B):\n",
        "    df = train_B.copy()\n",
        "    print(\"Step 1: Age, TestDate 파생...\")\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "\n",
        "    print(\"Step 2: B1 feature 생성...\")\n",
        "    feats[\"B1_acc_task1\"] = seq_rate(df[\"B1-1\"], \"1\")\n",
        "    feats[\"B1_rt_mean\"]   = seq_mean(df[\"B1-2\"])\n",
        "    feats[\"B1_rt_std\"]    = seq_std(df[\"B1-2\"])\n",
        "    feats[\"B1_acc_task2\"] = seq_rate(df[\"B1-3\"], \"1\")\n",
        "\n",
        "    print(\"Step 3: B2 feature 생성...\")\n",
        "    feats[\"B2_acc_task1\"] = seq_rate(df[\"B2-1\"], \"1\")\n",
        "    feats[\"B2_rt_mean\"]   = seq_mean(df[\"B2-2\"])\n",
        "    feats[\"B2_rt_std\"]    = seq_std(df[\"B2-2\"])\n",
        "    feats[\"B2_acc_task2\"] = seq_rate(df[\"B2-3\"], \"1\")\n",
        "\n",
        "    print(\"Step 4: B3 feature 생성...\")\n",
        "    feats[\"B3_acc_rate\"] = seq_rate(df[\"B3-1\"], \"1\")\n",
        "    feats[\"B3_rt_mean\"]  = seq_mean(df[\"B3-2\"])\n",
        "    feats[\"B3_rt_std\"]   = seq_std(df[\"B3-2\"])\n",
        "\n",
        "    print(\"Step 5: B4 feature 생성...\")\n",
        "    feats[\"B4_acc_rate\"] = seq_rate(df[\"B4-1\"], \"1\")\n",
        "    feats[\"B4_rt_mean\"]  = seq_mean(df[\"B4-2\"])\n",
        "    feats[\"B4_rt_std\"]   = seq_std(df[\"B4-2\"])\n",
        "\n",
        "    print(\"Step 6: B5 feature 생성...\")\n",
        "    feats[\"B5_acc_rate\"] = seq_rate(df[\"B5-1\"], \"1\")\n",
        "    feats[\"B5_rt_mean\"]  = seq_mean(df[\"B5-2\"])\n",
        "    feats[\"B5_rt_std\"]   = seq_std(df[\"B5-2\"])\n",
        "\n",
        "    print(\"Step 7: B6~B8 feature 생성...\")\n",
        "    feats[\"B6_acc_rate\"] = seq_rate(df[\"B6\"], \"1\")\n",
        "    feats[\"B7_acc_rate\"] = seq_rate(df[\"B7\"], \"1\")\n",
        "    feats[\"B8_acc_rate\"] = seq_rate(df[\"B8\"], \"1\")\n",
        "\n",
        "    print(\"Step 8: 시퀀스 컬럼 drop & concat...\")\n",
        "    seq_cols = [\n",
        "        \"B1-1\",\"B1-2\",\"B1-3\",\n",
        "        \"B2-1\",\"B2-2\",\"B2-3\",\n",
        "        \"B3-1\",\"B3-2\",\n",
        "        \"B4-1\",\"B4-2\",\n",
        "        \"B5-1\",\"B5-2\",\n",
        "        \"B6\",\"B7\",\"B8\"\n",
        "    ]\n",
        "    print(\"B 검사 데이터 전처리 완료\")\n",
        "    out = pd.concat([df.drop(columns=seq_cols, errors=\"ignore\"), feats], axis=1)\n",
        "    out.replace([np.inf,-np.inf], np.nan, inplace=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "nfcsGBZp8Poj"
      },
      "id": "nfcsGBZp8Poj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 때 사용한 파생 (그대로)\n",
        "def _has(df, cols):  return all(c in df.columns for c in cols)\n",
        "def _safe_div(a, b, eps=1e-6): return a / (b + eps)\n",
        "\n",
        "def add_features_A(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy(); eps = 1e-6\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    if _has(feats, [\"A1_rt_mean\",\"A1_resp_rate\"]):\n",
        "        feats[\"A1_speed_acc_tradeoff\"] = _safe_div(feats[\"A1_rt_mean\"], feats[\"A1_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A2_rt_mean\",\"A2_resp_rate\"]):\n",
        "        feats[\"A2_speed_acc_tradeoff\"] = _safe_div(feats[\"A2_rt_mean\"], feats[\"A2_resp_rate\"], eps)\n",
        "    if _has(feats, [\"A4_rt_mean\",\"A4_acc_rate\"]):\n",
        "        feats[\"A4_speed_acc_tradeoff\"] = _safe_div(feats[\"A4_rt_mean\"], feats[\"A4_acc_rate\"], eps)\n",
        "\n",
        "    for k in [\"A1\",\"A2\",\"A3\",\"A4\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    for name, base in [\n",
        "        (\"A1_rt_side_gap_abs\",  \"A1_rt_side_diff\"),\n",
        "        (\"A1_rt_speed_gap_abs\", \"A1_rt_speed_diff\"),\n",
        "        (\"A2_rt_cond1_gap_abs\", \"A2_rt_cond1_diff\"),\n",
        "        (\"A2_rt_cond2_gap_abs\", \"A2_rt_cond2_diff\"),\n",
        "        (\"A4_stroop_gap_abs\",   \"A4_stroop_diff\"),\n",
        "        (\"A4_color_gap_abs\",    \"A4_rt_color_diff\"),\n",
        "    ]:\n",
        "        if base in feats.columns:\n",
        "            feats[name] = feats[base].abs()\n",
        "\n",
        "    if _has(feats, [\"A3_valid_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_valid_invalid_gap\"] = feats[\"A3_valid_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A3_correct_ratio\",\"A3_invalid_ratio\"]):\n",
        "        feats[\"A3_correct_invalid_gap\"] = feats[\"A3_correct_ratio\"] - feats[\"A3_invalid_ratio\"]\n",
        "    if _has(feats, [\"A5_acc_change\",\"A5_acc_nonchange\"]):\n",
        "        feats[\"A5_change_nonchange_gap\"] = feats[\"A5_acc_change\"] - feats[\"A5_acc_nonchange\"]\n",
        "\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats\n",
        "\n",
        "def add_features_B(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    feats = df.copy(); eps = 1e-6\n",
        "    if _has(feats, [\"Year\",\"Month\"]):\n",
        "        feats[\"YearMonthIndex\"] = feats[\"Year\"] * 12 + feats[\"Month\"]\n",
        "\n",
        "    for k, acc_col, rt_col in [\n",
        "        (\"B1\", \"B1_acc_task1\", \"B1_rt_mean\"),\n",
        "        (\"B2\", \"B2_acc_task1\", \"B2_rt_mean\"),\n",
        "        (\"B3\", \"B3_acc_rate\",  \"B3_rt_mean\"),\n",
        "        (\"B4\", \"B4_acc_rate\",  \"B4_rt_mean\"),\n",
        "        (\"B5\", \"B5_acc_rate\",  \"B5_rt_mean\"),\n",
        "    ]:\n",
        "        if _has(feats, [rt_col, acc_col]):\n",
        "            feats[f\"{k}_speed_acc_tradeoff\"] = _safe_div(feats[rt_col], feats[acc_col], eps)\n",
        "\n",
        "    for k in [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\"]:\n",
        "        m, s = f\"{k}_rt_mean\", f\"{k}_rt_std\"\n",
        "        if _has(feats, [m, s]):\n",
        "            feats[f\"{k}_rt_cv\"] = _safe_div(feats[s], feats[m], eps)\n",
        "\n",
        "    parts = []\n",
        "    for k in [\"B4\",\"B5\"]:\n",
        "        if _has(feats, [f\"{k}_rt_cv\"]):\n",
        "            parts.append(0.25 * feats[f\"{k}_rt_cv\"].fillna(0))\n",
        "    for k in [\"B3\",\"B4\",\"B5\"]:\n",
        "        acc = f\"{k}_acc_rate\" if k not in [\"B1\",\"B2\"] else None\n",
        "        if k in [\"B1\",\"B2\"]:\n",
        "            acc = f\"{k}_acc_task1\"\n",
        "        if acc in feats:\n",
        "            parts.append(0.25 * (1 - feats[acc].fillna(0)))\n",
        "    for k in [\"B1\",\"B2\"]:\n",
        "        tcol = f\"{k}_speed_acc_tradeoff\"\n",
        "        if tcol in feats:\n",
        "            parts.append(0.25 * feats[tcol].fillna(0))\n",
        "    if parts:\n",
        "        feats[\"RiskScore_B\"] = sum(parts)\n",
        "\n",
        "    feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    return feats"
      ],
      "metadata": {
        "id": "kAhCLXRI8PmK"
      },
      "id": "kAhCLXRI8PmK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정렬/보정 (모델이 학습 때 본 피처 순서로)\n",
        "DROP_COLS = [\"Test_id\",\"Test\",\"PrimaryKey\",\"Age\",\"TestDate\"]\n",
        "\n",
        "def align_to_model(X_df, model):\n",
        "    feat_names = list(getattr(model, \"feature_name_\", []))\n",
        "    if not feat_names:\n",
        "        # fallback: 그냥 숫자형만\n",
        "        X = X_df.select_dtypes(include=[np.number]).copy()\n",
        "        return X.fillna(0.0)\n",
        "    X = X_df.drop(columns=[c for c in DROP_COLS if c in X_df.columns], errors=\"ignore\").copy()\n",
        "    # 누락 피처 0으로 채움\n",
        "    for c in feat_names:\n",
        "        if c not in X.columns:\n",
        "            X[c] = 0.0\n",
        "    # 초과 피처 드롭 + 순서 일치\n",
        "    X = X[feat_names]\n",
        "    return X.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n"
      ],
      "metadata": {
        "id": "0I93Ouiw8Pjs"
      },
      "id": "0I93Ouiw8Pjs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "def main():\n",
        "    # ---- 경로 변수 (필요에 따라 수정) ----\n",
        "    TEST_DIR  = \"./data\"              # test.csv, A.csv, B.csv, sample_submission.csv 위치\n",
        "    MODEL_DIR = \"./model\"             # lgbm_A.pkl, lgbm_B.pkl 위치\n",
        "    OUT_DIR   = \"./output\"\n",
        "    SAMPLE_SUB_PATH = os.path.join(TEST_DIR, \"/content/drive/MyDrive/data/sample_submission.csv\")\n",
        "    OUT_PATH  = os.path.join(OUT_DIR, \"submission.csv\")\n",
        "\n",
        "    # ---- 모델 로드 ----\n",
        "    print(\"Load models...\")\n",
        "    model_A = joblib.load(os.path.join(MODEL_DIR, \"lgbm_A.pkl\"))\n",
        "    model_B = joblib.load(os.path.join(MODEL_DIR, \"lgbm_B.pkl\"))\n",
        "    print(\" OK.\")\n",
        "\n",
        "    # ---- 테스트 데이터 로드 ----\n",
        "    print(\"Load test data...\")\n",
        "    meta = pd.read_csv(os.path.join(TEST_DIR, \"/content/drive/MyDrive/data/test.csv\"))\n",
        "    Araw = pd.read_csv(os.path.join(TEST_DIR, \"/content/drive/MyDrive/data/test/A.csv\"))\n",
        "    Braw = pd.read_csv(os.path.join(TEST_DIR, \"/content/drive/MyDrive/data/test/B.csv\"))\n",
        "    print(f\" meta={len(meta)}, Araw={len(Araw)}, Braw={len(Braw)}\")\n",
        "\n",
        "    # ---- 매핑 ----\n",
        "    A_df = meta.loc[meta[\"Test\"] == \"A\", [\"Test_id\", \"Test\"]].merge(Araw, on=\"Test_id\", how=\"left\")\n",
        "    B_df = meta.loc[meta[\"Test\"] == \"B\", [\"Test_id\", \"Test\"]].merge(Braw, on=\"Test_id\", how=\"left\")\n",
        "    print(f\" mapped: A={len(A_df)}, B={len(B_df)}\")\n",
        "\n",
        "    # ---- 전처리 → 파생 (학습과 동일) ----\n",
        "    A_feat = add_features_A(preprocess_A(A_df)) if len(A_df) else pd.DataFrame()\n",
        "    B_feat = add_features_B(preprocess_B(B_df)) if len(B_df) else pd.DataFrame()\n",
        "\n",
        "    # ---- 피처 정렬/보정 ----\n",
        "    XA = align_to_model(A_feat, model_A) if len(A_feat) else pd.DataFrame(columns=getattr(model_A,\"feature_name_\",[]))\n",
        "    XB = align_to_model(B_feat, model_B) if len(B_feat) else pd.DataFrame(columns=getattr(model_B,\"feature_name_\",[]))\n",
        "    print(f\" aligned: XA={XA.shape}, XB={XB.shape}\")\n",
        "\n",
        "    # ---- 예측 ----\n",
        "    print(\"Inference Model...\")\n",
        "    predA = model_A.predict_proba(XA)[:,1] if len(XA) else np.array([])\n",
        "    predB = model_B.predict_proba(XB)[:,1] if len(XB) else np.array([])\n",
        "\n",
        "    # ---- Test_id와 합치기 ----\n",
        "    subA = pd.DataFrame({\"Test_id\": A_df[\"Test_id\"].values, \"prob\": predA})\n",
        "    subB = pd.DataFrame({\"Test_id\": B_df[\"Test_id\"].values, \"prob\": predB})\n",
        "    probs = pd.concat([subA, subB], axis=0, ignore_index=True)\n",
        "\n",
        "    # ---- sample_submission 기반 결과 생성 (Label 컬럼에 0~1 확률 채움) ----\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "    sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "    # sample의 Test_id 순서에 맞추어 prob 병합\n",
        "    out = sample.merge(probs, on=\"Test_id\", how=\"left\")\n",
        "    out[\"Label\"] = out[\"prob\"].astype(float).fillna(0.0)\n",
        "    out = out.drop(columns=[\"prob\"])\n",
        "\n",
        "    out.to_csv(OUT_PATH, index=False)\n",
        "    print(f\"✅ Saved: {OUT_PATH} (rows={len(out)})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IYfk8fH8n5q",
        "outputId": "c1e437bf-d1d5-49a7-d798-61ea7de9257b"
      },
      "id": "5IYfk8fH8n5q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load models...\n",
            " OK.\n",
            "Load test data...\n",
            " meta=10, Araw=4, Braw=6\n",
            " mapped: A=4, B=6\n",
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: A1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 11634.69it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7509.94it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3012.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: A2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 8957.40it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 7136.20it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 5424.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: A3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 11514.90it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 6775.94it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 5729.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: A4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 9669.87it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3719.18it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 3566.59it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 2403.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: A5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 11244.78it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00, 10768.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: 시퀀스 컬럼 drop & concat...\n",
            "A 검사 데이터 전처리 완료\n",
            "Step 1: Age, TestDate 파생...\n",
            "Step 2: B1 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 21254.92it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 12633.45it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 7094.96it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 16194.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3: B2 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 15592.21it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10339.29it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 2875.77it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15205.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 4: B3 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 5926.95it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 12064.15it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 3584.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 5: B4 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 13443.28it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 5143.23it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 2326.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 6: B5 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 5814.65it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 4240.24it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 6300.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 7: B6~B8 feature 생성...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 13155.16it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 9757.98it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 7605.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 8: 시퀀스 컬럼 drop & concat...\n",
            "B 검사 데이터 전처리 완료\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " aligned: XA=(4, 62), XB=(6, 46)\n",
            "Inference Model...\n",
            "✅ Saved: ./output/submission.csv (rows=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#제출파일 생성"
      ],
      "metadata": {
        "id": "I17i0Mv4EmCl"
      },
      "id": "I17i0Mv4EmCl"
    },
    {
      "cell_type": "code",
      "source": [
        "# submit_dir 변수가 없어서 다시 정의\n",
        "from pathlib import Path\n",
        "\n",
        "submit_dir = Path(\"/content/drive/MyDrive/data/submit_package\")\n",
        "submit_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# script.py 다시 저장\n",
        "script_path = submit_dir / \"script.py\"\n",
        "script_path.write_text(script_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 결과 확인\n",
        "script_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EsHg53vbOP0I",
        "outputId": "16e4a35f-f36c-41a8-a502-b9b385027f41"
      },
      "id": "EsHg53vbOP0I",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'script.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1단계: script.py 생성 (inference.py와 동일 내용)\n",
        "\n",
        "script_py = \"\"\"\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from preprocess import preprocess_A, preprocess_B\n",
        "from features import add_features_A, add_features_B\n",
        "from align import align_to_model\n",
        "\n",
        "def inference(test_dir: str = \"./data\", model_dir: str = \"./model\", output_dir: str = \"./output\"):\n",
        "    sample_sub_path = os.path.join(test_dir, \"sample_submission.csv\")\n",
        "    out_path = os.path.join(output_dir, \"submission.csv\")\n",
        "\n",
        "    print(\"Loading models...\")\n",
        "    model_A = joblib.load(os.path.join(model_dir, \"lgbm_A.pkl\"))\n",
        "    model_B = joblib.load(os.path.join(model_dir, \"lgbm_B.pkl\"))\n",
        "    print(\"Models loaded.\")\n",
        "\n",
        "    print(\"Loading test data...\")\n",
        "    meta = pd.read_csv(os.path.join(test_dir, \"test.csv\"))\n",
        "    Araw = pd.read_csv(os.path.join(test_dir, \"A.csv\"))\n",
        "    Braw = pd.read_csv(os.path.join(test_dir, \"B.csv\"))\n",
        "\n",
        "    A_df = meta.loc[meta[\"Test\"] == \"A\", [\"Test_id\", \"Test\"]].merge(Araw, on=\"Test_id\", how=\"left\")\n",
        "    B_df = meta.loc[meta[\"Test\"] == \"B\", [\"Test_id\", \"Test\"]].merge(Braw, on=\"Test_id\", how=\"left\")\n",
        "\n",
        "    A_feat = add_features_A(preprocess_A(A_df)) if len(A_df) else pd.DataFrame()\n",
        "    B_feat = add_features_B(preprocess_B(B_df)) if len(B_df) else pd.DataFrame()\n",
        "\n",
        "    XA = align_to_model(A_feat, model_A) if len(A_feat) else pd.DataFrame(columns=getattr(model_A,\"feature_name_\",[]))\n",
        "    XB = align_to_model(B_feat, model_B) if len(B_feat) else pd.DataFrame(columns=getattr(model_B,\"feature_name_\",[]))\n",
        "\n",
        "    print(\"Running inference...\")\n",
        "    predA = model_A.predict_proba(XA)[:,1] if len(XA) else np.array([])\n",
        "    predB = model_B.predict_proba(XB)[:,1] if len(XB) else np.array([])\n",
        "\n",
        "    subA = pd.DataFrame({\"Test_id\": A_df[\"Test_id\"].values, \"prob\": predA})\n",
        "    subB = pd.DataFrame({\"Test_id\": B_df[\"Test_id\"].values, \"prob\": predB})\n",
        "    probs = pd.concat([subA, subB], axis=0, ignore_index=True)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    sample = pd.read_csv(sample_sub_path)\n",
        "    out = sample.merge(probs, on=\"Test_id\", how=\"left\")\n",
        "    out[\"Label\"] = out[\"prob\"].astype(float).fillna(0.0)\n",
        "    out.drop(columns=[\"prob\"], inplace=True)\n",
        "    out.to_csv(out_path, index=False)\n",
        "    print(f\"✅ Inference completed. Saved to: {out_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    inference()\n",
        "\"\"\"\n",
        "\n",
        "# 저장\n",
        "script_path = submit_dir / \"script.py\"\n",
        "script_path.write_text(script_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 결과 확인\n",
        "script_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "I-N_RuHtN2gr",
        "outputId": "ecb07e20-092d-46b2-eaa5-46a8423df191"
      },
      "id": "I-N_RuHtN2gr",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'script.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2단계: preprocess.py 생성\n",
        "\n",
        "preprocess_py = \"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "def convert_age(val):\n",
        "    if pd.isna(val): return np.nan\n",
        "    try:\n",
        "        base = int(str(val)[:-1])\n",
        "        return base if str(val)[-1] == \"a\" else base + 5\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "def split_testdate(val):\n",
        "    try:\n",
        "        v = int(val)\n",
        "        return v // 100, v % 100\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def seq_mean(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").mean() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_std(series):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: np.fromstring(x, sep=\",\").std() if x else np.nan\n",
        "    )\n",
        "\n",
        "def seq_rate(series, target=\"1\"):\n",
        "    return series.fillna(\"\").progress_apply(\n",
        "        lambda x: str(x).split(\",\").count(target) / len(x.split(\",\")) if x else np.nan\n",
        "    )\n",
        "\n",
        "def masked_mean_from_csv_series(cond_series, val_series, mask_val):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = (cond_arr == mask_val)\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts==0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\n",
        "def masked_mean_in_set_series(cond_series, val_series, mask_set):\n",
        "    cond_df = cond_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    val_df  = val_series.fillna(\"\").str.split(\",\", expand=True).replace(\"\", np.nan)\n",
        "    cond_arr = cond_df.to_numpy(dtype=float)\n",
        "    val_arr  = val_df.to_numpy(dtype=float)\n",
        "    mask = np.isin(cond_arr, list(mask_set))\n",
        "    with np.errstate(invalid=\"ignore\"):\n",
        "        sums = np.nansum(np.where(mask, val_arr, np.nan), axis=1)\n",
        "        counts = np.sum(mask, axis=1)\n",
        "        out = sums / np.where(counts == 0, np.nan, counts)\n",
        "    return pd.Series(out, index=cond_series.index)\n",
        "\"\"\"\n",
        "\n",
        "# 저장\n",
        "preprocess_path = submit_dir / \"preprocess.py\"\n",
        "preprocess_path.write_text(preprocess_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 완료 후 다음 단계로 안내\n",
        "preprocess_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BwYAEzo3PSmh",
        "outputId": "f8482cc2-d7e5-4d96-a869-c180dd946a88"
      },
      "id": "BwYAEzo3PSmh",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'preprocess.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3단계: features.py 생성\n",
        "\n",
        "features_py = \"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from preprocess import *\n",
        "\n",
        "def preprocess_A(df):\n",
        "    df = df.copy()\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "    feats[\"A1_resp_rate\"] = seq_rate(df[\"A1-3\"], \"1\")\n",
        "    feats[\"A1_rt_mean\"]   = seq_mean(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_std\"]    = seq_std(df[\"A1-4\"])\n",
        "    feats[\"A1_rt_left\"]   = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_right\"]  = masked_mean_from_csv_series(df[\"A1-1\"], df[\"A1-4\"], 2)\n",
        "    feats[\"A1_rt_side_diff\"] = feats[\"A1_rt_left\"] - feats[\"A1_rt_right\"]\n",
        "    feats[\"A1_rt_slow\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 1)\n",
        "    feats[\"A1_rt_fast\"]   = masked_mean_from_csv_series(df[\"A1-2\"], df[\"A1-4\"], 3)\n",
        "    feats[\"A1_rt_speed_diff\"] = feats[\"A1_rt_slow\"] - feats[\"A1_rt_fast\"]\n",
        "    df.drop(columns=[col for col in df.columns if col.startswith(\"A1\")], inplace=True)\n",
        "    return pd.concat([df, feats], axis=1)\n",
        "\n",
        "def preprocess_B(df):\n",
        "    df = df.copy()\n",
        "    df[\"Age_num\"] = df[\"Age\"].map(convert_age)\n",
        "    ym = df[\"TestDate\"].map(split_testdate)\n",
        "    df[\"Year\"] = [y for y, m in ym]\n",
        "    df[\"Month\"] = [m for y, m in ym]\n",
        "\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "    feats[\"B1_acc_task1\"] = seq_rate(df[\"B1-1\"], \"1\")\n",
        "    feats[\"B1_rt_mean\"]   = seq_mean(df[\"B1-2\"])\n",
        "    feats[\"B1_rt_std\"]    = seq_std(df[\"B1-2\"])\n",
        "    feats[\"B1_acc_task2\"] = seq_rate(df[\"B1-3\"], \"1\")\n",
        "    df.drop(columns=[col for col in df.columns if col.startswith(\"B1\")], inplace=True)\n",
        "    return pd.concat([df, feats], axis=1)\n",
        "\n",
        "def _has(df, cols): return all(c in df.columns for c in cols)\n",
        "def _safe_div(a, b, eps=1e-6): return a / (b + eps)\n",
        "\n",
        "def add_features_A(df):\n",
        "    feats = df.copy()\n",
        "    if _has(feats, [\"A1_rt_mean\",\"A1_resp_rate\"]):\n",
        "        feats[\"A1_speed_acc_tradeoff\"] = _safe_div(feats[\"A1_rt_mean\"], feats[\"A1_resp_rate\"])\n",
        "    return feats\n",
        "\n",
        "def add_features_B(df):\n",
        "    feats = df.copy()\n",
        "    if _has(feats, [\"B1_rt_mean\",\"B1_acc_task1\"]):\n",
        "        feats[\"B1_speed_acc_tradeoff\"] = _safe_div(feats[\"B1_rt_mean\"], feats[\"B1_acc_task1\"])\n",
        "    return feats\n",
        "\"\"\"\n",
        "\n",
        "# 저장\n",
        "features_path = submit_dir / \"features.py\"\n",
        "features_path.write_text(features_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 완료 후 다음 단계 안내\n",
        "features_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "12AfiYUVPW8f",
        "outputId": "83c21743-f7d1-4e4a-abb2-b74f2b20c7a2"
      },
      "id": "12AfiYUVPW8f",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'features.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4단계: align.py 생성\n",
        "\n",
        "align_py = \"\"\"\n",
        "import pandas as pd\n",
        "\n",
        "DROP_COLS = [\"Test_id\", \"Test\", \"PrimaryKey\", \"Age\", \"TestDate\"]\n",
        "\n",
        "def align_to_model(X_df, model):\n",
        "    feat_names = list(getattr(model, \"feature_name_\", []))\n",
        "    if not feat_names:\n",
        "        X = X_df.select_dtypes(include=[float, int])\n",
        "        return X.fillna(0.0)\n",
        "\n",
        "    X = X_df.drop(columns=[c for c in DROP_COLS if c in X_df.columns], errors=\"ignore\").copy()\n",
        "    for c in feat_names:\n",
        "        if c not in X.columns:\n",
        "            X[c] = 0.0\n",
        "    X = X[feat_names]\n",
        "    return X.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
        "\"\"\"\n",
        "\n",
        "# 저장\n",
        "align_path = submit_dir / \"align.py\"\n",
        "align_path.write_text(align_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 다음 단계로\n",
        "align_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AAkYpNl0PaTC",
        "outputId": "2eb00e26-9f59-4642-96f1-d150799349c2"
      },
      "id": "AAkYpNl0PaTC",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'align.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5단계: requirements.txt 생성\n",
        "\n",
        "requirements_txt = \"\"\"\n",
        "pandas\n",
        "numpy\n",
        "lightgbm\n",
        "joblib\n",
        "tqdm\n",
        "\"\"\"\n",
        "\n",
        "# 저장\n",
        "requirements_path = submit_dir / \"requirements.txt\"\n",
        "requirements_path.write_text(requirements_txt.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 다음 단계로\n",
        "requirements_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SIKyP_PEPdnS",
        "outputId": "622d41be-47f0-4788-828f-0fe25c9b9ae0"
      },
      "id": "SIKyP_PEPdnS",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'requirements.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# README.md 내용\n",
        "readme_md = \"\"\"\n",
        "# 교통사고 예측 AI - 코드 제출 가이드\n",
        "\n",
        "이 코드는 교통사고 예측 AI 경진대회를 위한 추론 스크립트입니다.\n",
        "\n",
        "## 📁 디렉토리 구조\n",
        "submit_package/\n",
        "├── script.py             # 메인 추론 스크립트 (필수)\n",
        "├── preprocess.py         # 공통 전처리 함수\n",
        "├── features.py           # A/B 전처리 및 피처 생성\n",
        "├── align.py              # 모델 입력 피처 정렬\n",
        "├── requirements.txt      # 필요 패키지 목록\n",
        "├── README.md             # 실행 방법 설명\n",
        "├── model/\n",
        "│   ├── lgbm_A.pkl\n",
        "│   └── lgbm_B.pkl\n",
        "└── data/\n",
        "    ├── test.csv\n",
        "    ├── A.csv\n",
        "    ├── B.csv\n",
        "    └── sample_submission.csv\n",
        "\n",
        "## 🚀 실행 방법\n",
        "\n",
        "python script.py\n",
        "\n",
        "- 평가 시스템에서는 기본 경로(./data, ./model, ./output)를 기준으로 실행됩니다.\n",
        "\n",
        "## 💡 주의 사항\n",
        "\n",
        "- 인터넷 없이 오프라인 환경에서 실행됩니다.\n",
        "- 전체 실행 시간은 30분 이내여야 합니다.\n",
        "- 모델 및 데이터 파일은 반드시 해당 폴더에 위치시켜야 합니다.\n",
        "\n",
        "---\n",
        "감사합니다!\n",
        "\"\"\"\n",
        "\n",
        "# 파일 저장\n",
        "readme_path = submit_dir / \"README.md\"\n",
        "readme_path.write_text(readme_md.strip(), encoding=\"utf-8\")\n",
        "\n",
        "readme_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8PD5ECIsQAAS",
        "outputId": "5e864744-2cc7-40f6-fd77-e16a1ccd3388"
      },
      "id": "8PD5ECIsQAAS",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'README.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7단계: model/ 및 data/ 폴더 생성\n",
        "\n",
        "model_dir = submit_dir / \"model\"\n",
        "data_dir = submit_dir / \"data\"\n",
        "\n",
        "model_dir.mkdir(exist_ok=True)\n",
        "data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# 생성된 폴더 목록 확인\n",
        "folder_list = sorted([f.name for f in submit_dir.iterdir() if f.is_dir()])\n",
        "folder_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy4gYAmrQFUN",
        "outputId": "b86a3ed1-fd3f-4e42-bd51-b36da6a4be34"
      },
      "id": "cy4gYAmrQFUN",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'model']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# script.py 수정: 올바른 import 경로로 변경\n",
        "fixed_script_py = \"\"\"\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from features import preprocess_A, preprocess_B\n",
        "from features import add_features_A, add_features_B\n",
        "from align import align_to_model\n",
        "\n",
        "def inference(test_dir: str = \"./data\", model_dir: str = \"./model\", output_dir: str = \"./output\"):\n",
        "    sample_sub_path = os.path.join(test_dir, \"sample_submission.csv\")\n",
        "    out_path = os.path.join(output_dir, \"submission.csv\")\n",
        "\n",
        "    print(\"Loading models...\")\n",
        "    model_A = joblib.load(os.path.join(model_dir, \"lgbm_A.pkl\"))\n",
        "    model_B = joblib.load(os.path.join(model_dir, \"lgbm_B.pkl\"))\n",
        "    print(\"Models loaded.\")\n",
        "\n",
        "    print(\"Loading test data...\")\n",
        "    meta = pd.read_csv(os.path.join(test_dir, \"test.csv\"))\n",
        "    Araw = pd.read_csv(os.path.join(test_dir, \"A.csv\"))\n",
        "    Braw = pd.read_csv(os.path.join(test_dir, \"B.csv\"))\n",
        "\n",
        "    A_df = meta.loc[meta[\"Test\"] == \"A\", [\"Test_id\", \"Test\"]].merge(Araw, on=\"Test_id\", how=\"left\")\n",
        "    B_df = meta.loc[meta[\"Test\"] == \"B\", [\"Test_id\", \"Test\"]].merge(Braw, on=\"Test_id\", how=\"left\")\n",
        "\n",
        "    A_feat = add_features_A(preprocess_A(A_df)) if len(A_df) else pd.DataFrame()\n",
        "    B_feat = add_features_B(preprocess_B(B_df)) if len(B_df) else pd.DataFrame()\n",
        "\n",
        "    XA = align_to_model(A_feat, model_A) if len(A_feat) else pd.DataFrame(columns=getattr(model_A,\"feature_name_\",[]))\n",
        "    XB = align_to_model(B_feat, model_B) if len(B_feat) else pd.DataFrame(columns=getattr(model_B,\"feature_name_\",[]))\n",
        "\n",
        "    print(\"Running inference...\")\n",
        "    predA = model_A.predict_proba(XA)[:,1] if len(XA) else np.array([])\n",
        "    predB = model_B.predict_proba(XB)[:,1] if len(XB) else np.array([])\n",
        "\n",
        "    subA = pd.DataFrame({\"Test_id\": A_df[\"Test_id\"].values, \"prob\": predA})\n",
        "    subB = pd.DataFrame({\"Test_id\": B_df[\"Test_id\"].values, \"prob\": predB})\n",
        "    probs = pd.concat([subA, subB], axis=0, ignore_index=True)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    sample = pd.read_csv(sample_sub_path)\n",
        "    out = sample.merge(probs, on=\"Test_id\", how=\"left\")\n",
        "    out[\"Label\"] = out[\"prob\"].astype(float).fillna(0.0)\n",
        "    out.drop(columns=[\"prob\"], inplace=True)\n",
        "    out.to_csv(out_path, index=False)\n",
        "    print(f\"✅ Inference completed. Saved to: {out_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    inference()\n",
        "\"\"\"\n",
        "\n",
        "# 덮어쓰기 저장\n",
        "script_path = submit_dir / \"script.py\"\n",
        "script_path.write_text(fixed_script_py.strip(), encoding=\"utf-8\")\n",
        "\n",
        "# 완료 알림\n",
        "script_path.name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "y_1uWbhiUcr0",
        "outputId": "ef798b4a-f893-4c8d-8bbf-9e237351e83f"
      },
      "id": "y_1uWbhiUcr0",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'script.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gimin_py38",
      "language": "python",
      "name": "gimin_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}