{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxgZAqMIyPbf7aMPAoNLIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kjy-0429/NLP_2025/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EA%B8%B0%EB%B3%B8_%EC%97%B0%EC%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##탠서 생성 방법"
      ],
      "metadata": {
        "id": "TJPAHGwFqujd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g1Z6zzGqiSh",
        "outputId": "87b44c9b-dc57-4109-823d-b10017f1305d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1차원 텐서: tensor([1, 2, 3])\n",
            "2차원 텐서:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "##리스트나 배열로부터 직접 생성\n",
        "\n",
        "import torch\n",
        "\n",
        "tensor1d = torch.tensor([1, 2,3])\n",
        "print(f'1차원 텐서: {tensor1d}')\n",
        "\n",
        "tensor2d = torch.tensor([[1, 2,3],\n",
        "[4, 5, 6]])\n",
        "print(f'2차원 텐서:\\n {tensor2d}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###특수 함수로 생성\n",
        "\n",
        "zeros_tensor = torch.zeros((3, 3))\n",
        "ones_tensor = torch.ones((2,4))\n",
        "full_tensor = torch.full((2, 2), 7)\n",
        "# 2×2 텐서를 7로 채움\n",
        "\n",
        "arange_tensor = torch.arange(0, 10, step=2)\n",
        "# 0, 2, 4, 6, 8\n",
        "linspace_tensor = torch.linspace(0, 1, steps=5)\n",
        "# 0, 0.25, 0.5, 0.75, 1\n",
        "\n",
        "print(f'zeros_tensor:\\n {zeros_tensor}')\n",
        "print(f'ones_tensor:\\n {ones_tensor}')\n",
        "print(f'full_tensor:\\n {full_tensor}')\n",
        "print(f'arange_tensor: {arange_tensor}')\n",
        "print(f'linspace_tensor: {linspace_tensor}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v78d1zuwqrRN",
        "outputId": "0d085bb4-7166-49ac-a152-1b777bca87fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zeros_tensor:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "ones_tensor:\n",
            " tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "full_tensor:\n",
            " tensor([[7, 7],\n",
            "        [7, 7]])\n",
            "arange_tensor: tensor([0, 2, 4, 6, 8])\n",
            "linspace_tensor: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#무작위 텐서 생성\n",
        "\n",
        "# rand: [0,1] 범위의 균일 분포\n",
        "rand_tensor = torch.rand((3,3))\n",
        "\n",
        "# randn: 평균 0, 표준 편차 1의 정규 분포\n",
        "randn_tensor = torch.randn((2, 2))\n",
        "\n",
        "print(f'rand_tensor:\\n {rand_tensor}')\n",
        "print(f'randn_tensor:\\n {randn_tensor}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXuRp9lIqrIJ",
        "outputId": "56160c7a-5f36-4b43-aa3a-c5c1c75c5ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rand_tensor:\n",
            " tensor([[0.0732, 0.3634, 0.9747],\n",
            "        [0.5826, 0.8088, 0.9065],\n",
            "        [0.3433, 0.8886, 0.8047]])\n",
            "randn_tensor:\n",
            " tensor([[-0.1910, -0.9584],\n",
            "        [-0.2957, -1.5655]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 설정\n",
        "\n",
        "# float 텐서\n",
        "float_tensor = torch.tensor([1,2,3], dtype=torch.float32)\n",
        "\n",
        "# int 텐서\n",
        "int_tensor = torch.tensor([1, 2,3], dtype=torch.int64)\n",
        "\n",
        "print(f'float_tensor dtype: {float_tensor.dtype}')\n",
        "print(f'int_tensor dtype: {int_tensor.dtype}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC-i2JmAtGZB",
        "outputId": "0462be97-efb5-4999-c71d-755df2eae656"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float_tensor dtype: torch.float32\n",
            "int_tensor dtype: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예시\n",
        "def explore_tensor_dimensions():\n",
        "\n",
        "# 차원별 텐서의 실제 의미와 활용법\n",
        "\n",
        "  print(\"텐서 차원별 탐형을 시작합니다!\")\n",
        "  print(\"=\" * 50)\n",
        "\n",
        "  # 0차원: 스칼라(딥러닝에서 손실값 등)\n",
        "  loss_value = torch.tensor(0.245)\n",
        "  print(f\"0차원 (스칼라): {loss_value}\")\n",
        "  print(\" 실제 의미: 모델의 손실값\")\n",
        "  print(f\"모양: {loss_value.shape}\")\n",
        "  print(f\"차원 수: {loss_value.dim()}\\n\")\n",
        "\n",
        "  # 1차원: 벡터(단어 임베딩, 특성 벡터 등)\n",
        "  word_embedding = torch.tensor([0.2, -0.1, 0.8, 0.5])\n",
        "  print(f\"1차원 (벡터): {word_embedding}\")\n",
        "  print(\" 실제 의미: '사랑'이라는 단어의 4차원 임베딩\")\n",
        "  print(f\" 모양: {word_embedding.shape}\")\n",
        "  print(f\" 차원 수: {word_embedding.dim()}\\n\")\n",
        "\n",
        "  # 2차원: 행럴(이미지, 가중치 행럴 등)\n",
        "  grayscale_image = torch.randint(0, 256, (4, 4))\n",
        "  print(f\"2차원 (행렬):\\n{grayscale_image}\")\n",
        "  print(\" 실제 의미: 4×4 픽셀 혹백 이미지\")\n",
        "  print(f\"모양: {grayscale_image.shape}\")\n",
        "  print(f\" 차원 수: {grayscale_image.dim()}\\n\")\n",
        "\n",
        "  # 3차원: 컬러 이미지(높이 × 너비 × 채널)\n",
        "  color_image = torch.randint(0, 256, (3, 4, 4)) # RGB 각 채널\n",
        "  print(f\"3차원 (컬러 이미지): 모양 {color_image.shape}\")\n",
        "  print(\" 실제 의미: 4×4 픽셀 컬러 이미지 (RGB)\")\n",
        "  print(\" 해석: 3개 채널 × 4높이 × 4너비\")\n",
        "  print(f\" 차원 수: {color_image.dim( )}\\n\")\n",
        "\n",
        "  # 4차원: 배치 이미(배치× 채널× 높이 × 너비)\n",
        "  batch_images = torch.randint(0, 256, (2, 3, 4, 4))\n",
        "  print(f\"4차원 (이미지 배치): 모양 {batch_images.shape}\")\n",
        "  print(\" 실제 의미: 2장의 4×4 컬러 이미지 묶음\")\n",
        "  print(\" 해석: 2배치 × 3채널 × 4높이 × 4너비\")\n",
        "  print(f\" 차원 수: {batch_images.dim()}\\n\")\n",
        "\n",
        "  print(\"딥러닝에서 각 자원의 의미:\")\n",
        "  print(\" @ 배치 자원: 한 번에 처리할 데이터 개수\")\n",
        "  print(\" @ 특성 차원: 데이터의 특징 개수\")\n",
        "  print(\" 공간 차원: 이미지의 높이, 너비\")\n",
        "\n",
        "# 실행\n",
        "explore_tensor_dimensions()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtz8FFPftVBz",
        "outputId": "7777e4dc-550d-4141-a535-370c206bd23a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텐서 차원별 탐형을 시작합니다!\n",
            "==================================================\n",
            "0차원 (스칼라): 0.24500000476837158\n",
            " 실제 의미: 모델의 손실값\n",
            "모양: torch.Size([])\n",
            "차원 수: 0\n",
            "\n",
            "1차원 (벡터): tensor([ 0.2000, -0.1000,  0.8000,  0.5000])\n",
            " 실제 의미: '사랑'이라는 단어의 4차원 임베딩\n",
            " 모양: torch.Size([4])\n",
            " 차원 수: 1\n",
            "\n",
            "2차원 (행렬):\n",
            "tensor([[230, 193,  50, 210],\n",
            "        [ 92, 158, 142,  64],\n",
            "        [ 49,  36, 194,  54],\n",
            "        [ 68, 141, 194, 194]])\n",
            " 실제 의미: 4×4 픽셀 혹백 이미지\n",
            "모양: torch.Size([4, 4])\n",
            " 차원 수: 2\n",
            "\n",
            "3차원 (컬러 이미지): 모양 torch.Size([3, 4, 4])\n",
            " 실제 의미: 4×4 픽셀 컬러 이미지 (RGB)\n",
            " 해석: 3개 채널 × 4높이 × 4너비\n",
            " 차원 수: 3\n",
            "\n",
            "4차원 (이미지 배치): 모양 torch.Size([2, 3, 4, 4])\n",
            " 실제 의미: 2장의 4×4 컬러 이미지 묶음\n",
            " 해석: 2배치 × 3채널 × 4높이 × 4너비\n",
            " 차원 수: 4\n",
            "\n",
            "딥러닝에서 각 자원의 의미:\n",
            " @ 배치 자원: 한 번에 처리할 데이터 개수\n",
            " @ 특성 차원: 데이터의 특징 개수\n",
            " 공간 차원: 이미지의 높이, 너비\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###산술 연산"
      ],
      "metadata": {
        "id": "WPkwE9iv6d5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#기초 연산\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"b - a = {b - a}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "print(f\"b / a = {b /a}\")\n",
        "\n",
        "# tensor([5, 7, 9])\n",
        "# tensor([3, 3, 3])\n",
        "# tensor([4, 10, 18])\n",
        "# tensor([4.0000, 2.5000, 2.0000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ6ToYgntU_n",
        "outputId": "70a72018-7b92-40e2-f2ee-8d36bafc6453"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = tensor([5, 7, 9])\n",
            "b - a = tensor([3, 3, 3])\n",
            "a * b = tensor([ 4, 10, 18])\n",
            "b / a = tensor([4.0000, 2.5000, 2.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#스칼라와의 연산\n",
        "print(f\"a + 10 = {a + 10}\")\n",
        "print(f\"b * 2 = {b * 2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVfSf7IV6iAq",
        "outputId": "bc934cf6-4297-4994-b72f-938ee40b3085"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + 10 = tensor([11, 12, 13])\n",
            "b * 2 = tensor([ 8, 10, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#브로드 캐스\n",
        "\n",
        "a = torch.tensor([1, 2, 3])\n",
        "\n",
        "b = torch.tensor([10])\n",
        "\n",
        "# 브로드캐스팅: b가 자동으로 [10, 10, 10]으로 확장\n",
        "print(f'a + b = {a + b}') # tensor([11, 12, 13])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5MImwAk6h6n",
        "outputId": "82d24893-1f15-4c25-edbb-35d8c761ce53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = tensor([11, 12, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#인덱싱, 슬라이싱\n",
        "\n",
        "tensor2d = torch.tensor([[10, 20, 30],\n",
        "[40, 50, 60],\n",
        "[70,80,90]])\n",
        "\n",
        "# 특정 요소: (0,1)\n",
        "print(f'tensor2d[0, 1]= {tensor2d[0, 1]}') # 20\n",
        "\n",
        "# 행 슬라이싱: 1행부터 끝까지\n",
        "print(f'tensor2d[1:, :] =\\n {tensor2d[1:, :]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TJDWiBJ8JgZ",
        "outputId": "e3eac210-86f6-4a2a-a222-165a64b10436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor2d[0, 1]= 20\n",
            "tensor2d[1:, :] =\n",
            " tensor([[40, 50, 60],\n",
            "        [70, 80, 90]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#불리언 마스킹\n",
        "\n",
        "mask = tensor2d > 50\n",
        "print(f'mask:\\n {mask}')\n",
        "print(f'50보다 큰 값들: {tensor2d[mask]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tM1yGJ78Jd_",
        "outputId": "cc9623ec-6d45-4798-b2a0-f293958323ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask:\n",
            " tensor([[False, False, False],\n",
            "        [False, False,  True],\n",
            "        [ True,  True,  True]])\n",
            "50보다 큰 값들: tensor([60, 70, 80, 90])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#차원 변경\n",
        "tensor_flat = torch.arange(6) # [0,1,2,3,4,5]\n",
        "reshaped = tensor_flat.view(2, 3)\n",
        "print(f'reshaped:\\n {reshaped}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXpzoWHI8ODU",
        "outputId": "5e23684b-e0f9-409f-bb52-39b2d06341d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reshaped:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###고급 텐서 조작"
      ],
      "metadata": {
        "id": "CeEv1dyK8a05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서 합치기\n",
        "\n",
        "t1 = torch.tensor([1, 2,3])\n",
        "t2= torch.tensor([4, 5,6])\n",
        "\n",
        "# cat: 주어진 차원을 따라 텐서를 이어 붙임\n",
        "cat_result = torch.cat((t1, t2), dim=0) # shape: (6,)\n",
        "print(f'cat_result: {cat_result}')\n",
        "\n",
        "# stack: 새 차원을 만들어 텐서를 쌓음\n",
        "stack_result = torch.stack((t1, t2), dim=0) # shape: (2,3)\n",
        "print(f'stack_result:\\n {stack_result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfR6C0nS8Upw",
        "outputId": "56bad9f9-d823-4726-9f4c-9aad1431ad65"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat_result: tensor([1, 2, 3, 4, 5, 6])\n",
            "stack_result:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서 나누기\n",
        "\n",
        "big_tensor = torch.arange(10) # [0,1,2,3,4,5,6,7,8,9]\n",
        "\n",
        "# split: 특정 크기씩 잘라 리스트로 반환\n",
        "split_result = torch.split(big_tensor, split_size_or_sections=3)\n",
        "print(f'split_result: {split_result}')\n",
        "\n",
        "# chunk: 개수 기준으로 나눔\n",
        "chunk_result = torch.chunk(big_tensor, chunks=3)\n",
        "print(f'chunk_result: {chunk_result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMh_4S6T8Unm",
        "outputId": "d79def89-b8b2-4c04-f026-b021b1a538bb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split_result: (tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9]))\n",
            "chunk_result: (tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]), tensor([8, 9]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#차원 조작하기\n",
        "\n",
        "matrix = torch.tensor([[1, 2, 3],\n",
        "[4, 5, 6]])\n",
        "transposed = matrix.t() # matrix.transpose(0, 1)\n",
        "print(f'transposed:\\n {transposed}')\n",
        "\n",
        "# 3차원 예시\n",
        "tensor_3d = torch.randn(2, 3, 4)\n",
        "permute_result = tensor_3d.permute(2,1, 0) # 차원 순서 바꾸기\n",
        "\n",
        "# squeeze/unsqueeze: 차원이 1인 축을 제거/추가\n",
        "x = torch.tensor([[[1, 2, 3]]])\n",
        "squeezed = x.squeeze ()\n",
        "unsqueezed = squeezed.unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0bq6sdG8UlS",
        "outputId": "68286eac-3bfc-4a9b-857d-df7c318e8159"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transposed:\n",
            " tensor([[1, 4],\n",
            "        [2, 5],\n",
            "        [3, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###텐서와 NumPy 배열 간 상호 변환"
      ],
      "metadata": {
        "id": "lwQrNgeg-B-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NumPy 배열 → 파이토치 텐서\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np_arr = np.array([1,2,3])\n",
        "tensor_from_np=torch.from_numpy(np_arr)\n",
        "print(f'tensor_from_np: {tensor_from_np}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3CaLqm990pW",
        "outputId": "e301bcf6-f987-45cc-eeb7-8c19c6a0ebd2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor_from_np: tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#파이토치 텐서 → NumPy 배열\n",
        "\n",
        "np_from_tensor = tensor_from_np.numpy()\n",
        "print(f'np_from_tensor: {np_from_tensor}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3XXy2JZ90ly",
        "outputId": "25a4c53f-00fc-4e49-cffb-8ac6e31a3d33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np_from_tensor: [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU 텐서와 NumPy 배열의 메모리 공유\n",
        "\n",
        "# NumPy 배열 생성\n",
        "np_arr = np.array([1, 2, 3])\n",
        "\n",
        "# NumPy 배열을 파이토치 텐서로 변환(메모리 공유)\n",
        "tensor_from_np=torch.from_numpy(np_arr)\n",
        "print(f'변경 전 tensor_from_np: {tensor_from_np}')\n",
        "\n",
        "# NumPy 배열의 첫 번째 원소 수정\n",
        "np_arr[0] = 100\n",
        "print(f'변경 후 tensor_from_np: {tensor_from_np}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypSDeeJWABoU",
        "outputId": "7db18223-f322-4e0c-94f5-3b2cacb44355"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "변경 전 tensor_from_np: tensor([1, 2, 3])\n",
            "변경 후 tensor_from_np: tensor([100,   2,   3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "  # GPU에서 텐서 생성(device='cuda')\n",
        "  gpu_tensor = torch.tensor([1, 2, 3], device='cuda')\n",
        "  # GPU 텐서를 CPU로 이동 후 NumPy 배열로 변환\n",
        "  np_from_gpu = gpu_tensor.cpu().numpy()\n",
        "  print(f'GPU 텐서 -> NumPy 배열: {np_from_gpu}')\n",
        "else:\n",
        "  print('CUDA를 사용할 수 없습니다. GPU가 지원되지 않는 환경입니다. ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvBLgoTRAS_d",
        "outputId": "6eb7d5c9-0770-4049-f71b-50a3df44c3ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 텐서 -> NumPy 배열: [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#텐서의 GPU활용"
      ],
      "metadata": {
        "id": "p2FEqyyvCz_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU 확인\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU 사용 가능!\")\n",
        "else:\n",
        "  print(\"GPU를 사용할 수 없습니다. CPU 모드로 실행합니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrW0nQuoAS9L",
        "outputId": "c4c27ce4-5d4c-43a6-9976-9bb0b412da2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 사용 가능!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서를 GPU로 이동\n",
        "\n",
        "# GPU 사용 가능 여부에 따라 'cuda' 또는 'cpu' 선택\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"사용할 디바이스: {device}\")\n",
        "\n",
        "# 텐서 생성 후 지정한 디바이스로 이동\n",
        "x = torch.tensor([1.0, 2.0, 3.0]).to(device)\n",
        "print(f\"x가 위치한 디바이스: {x.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzxAq4WfABgD",
        "outputId": "e79407d3-7816-4967-819d-15ec22dcc61b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용할 디바이스: cuda\n",
            "x가 위치한 디바이스: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU에서 생성된 텐서 ×를 CPU로 이동\n",
        "x_cpu = x.cpu()\n",
        "print(f'x_cpu가 위치한 디바이스: {x_cpu.device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfxM3eSLDVqt",
        "outputId": "b42a621e-f7ec-4953-8f96-1b26a98862ad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_cpu가 위치한 디바이스: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#예제"
      ],
      "metadata": {
        "id": "carlpbYtEu_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#성능비교(예제)\n",
        "\n",
        "import time\n",
        "\n",
        "size = 10000 # 행렬 크기를 10,000 x10,000으로 설정\n",
        "\n",
        "# CPU에서의 행렬 곱셈 수행\n",
        "a_cpu = torch.rand((size, size))\n",
        "b_cpu = torch.rand((size, size))\n",
        "\n",
        "start_time = time.time()\n",
        "_= torch.mm(a_cpu, b_cpu) # 행렬 곱셈\n",
        "cpu_time = time. time() - start_time\n",
        "print(f'CPU matmul time: {cpu_time}')\n",
        "\n",
        "# GPU 사용 시: 동일한 행렬을 GPU로 이동하여 행렬 곱셈 수행\n",
        "if torch.cuda.is_available():\n",
        "  a_gpu = a_cpu.to(device)\n",
        "  b_gpu = b_cpu.to(device)\n",
        "\n",
        "  # GPU 연산은 비동기적이므로 연산 완료를 위해 동기화 필요\n",
        "  torch.cuda.synchronize()\n",
        "  start_time = time. time()\n",
        "  _= torch.mm(a_gpu, b_gpu)\n",
        "  torch.cuda.synchronize() # 연산 완료 후 동기화\n",
        "  gpu_time = time.time() - start_time\n",
        "  print(f'GPU matmul time: {gpu_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGQRAZJ-D85S",
        "outputId": "c8d1df56-d307-4cb2-9e3c-f0031490f0ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU matmul time: 16.113563776016235\n",
            "GPU matmul time: 0.6880171298980713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1.텐서 생성\n",
        "# torch.arange를 사용해 1부터 5까지의 정수를 담은 텐서 a와 6부터 10까지의 정수를 담은 텐서 b를 생성\n",
        "a = torch.arange(1, 6) # 결과: tensor([1, 2, 3, 4, 5])\n",
        "b = torch.arange(6, 11) # 걸과: tensor([ 6, 7, 8, 9, 10])\n",
        "\n",
        "#2.기본 민산\n",
        "# 텐서 a와 b의 원소별 덧셈과 곱샘을 수행한다.\n",
        "# 결과: tensor([ 7, 9, 11, 13, 15])\n",
        "# 걸과: tensor([ 6, 14, 24, 36, 50])\n",
        "\n",
        "print(f\"a + b = {a + b}\")\n",
        "print(f\"a * b = {a * b}\")\n",
        "\n",
        "#3.브로드캐스팅\n",
        "#텐서 c는 (3,1) 형태로 생성되며, 텐서 d는 (3,) 형태이다.\n",
        "# 두 텐서를 더하면 브로드캐스딩 규칙에 따라 d가 (3,1)로 확장되어 (3,3) 형타의 결과가 생성된다.\n",
        "c= torch. tensor([[1], [2], [3]]) # shape: (3,1)\n",
        "d= torch.tensor([10, 20, 30])\n",
        "print(f\"브로드캐스팀 c + d:\\n {c + d}\")\n",
        "\n",
        "# 4. NumPy 비교\n",
        "# 텐서 a와 b를 NunPy 배열로 변환한 후 동일한 연산을 수행하여 결과를 비교한다.\n",
        "np_a = a.numpy()\n",
        "np_b = b.numpy()\n",
        "np_result = np_a + np_b\n",
        "pt_result = a + b\n",
        "print(f\"NumPy 덧셈 결과: {np_result}\")\n",
        "print(f\"PyTorch 덧셈 결과: {pt_result}\")\n",
        "\n",
        "pt_result = a + b\n",
        "\n",
        "# 5. GPU 성능 비교(선택)\n",
        "# 만약 GPU가 사용할 수 있으면 대규모 행럴 곱셈을 통해 CPU와 GPU 연산 시간을 비교한다.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 크기가 큰 랜덤 텐서 생성(10,000×10,000)\n",
        "x_cpu = torch.randn((10000, 10000))\n",
        "y_cpu = torch.randn((10000, 10088))\n",
        "\n",
        "# CPU에서의 행렬 곱셈 연산 시간 측정\n",
        "start = time.time()\n",
        "_= torch.mm(x_cpu, y_cpu)\n",
        "cpu_time = time.time() - start\n",
        "print(f\"CPU matmul time: {cpu_time :.4f}sec\")\n",
        "\n",
        "# GPU가 사용할 수 있는 경우 동일한 연산을 GPU에서 수행한다.\n",
        "# 생성한 덴서를 GPU로 이동\n",
        "x_gpu = x_cpu.to(device)\n",
        "y_gpu = y_cpu.to(device)\n",
        "\n",
        "# GPU 연산은 비동기적으로 수청되므로 걸과 측정을 위해 동기화한다.\n",
        "torch.cuda.synchronize()\n",
        "start = time. time()\n",
        "_= torch.mm(x_gpu, y_gpu)\n",
        "torch.cuda.synchronize()\n",
        "gpu_time = time.time() - start\n",
        "print(f\"GPU matmul time: {gpu_time :.4f}sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5x6wNGrEnuX",
        "outputId": "eae18d2b-bad3-4a91-e543-706aac0181c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = tensor([ 7,  9, 11, 13, 15])\n",
            "a * b = tensor([ 6, 14, 24, 36, 50])\n",
            "브로드캐스팀 c + d:\n",
            " tensor([[11, 21, 31],\n",
            "        [12, 22, 32],\n",
            "        [13, 23, 33]])\n",
            "NumPy 덧셈 결과: [ 7  9 11 13 15]\n",
            "PyTorch 덧셈 결과: tensor([ 7,  9, 11, 13, 15])\n",
            "CPU matmul time: 17.3328sec\n",
            "GPU matmul time: 0.5352sec\n"
          ]
        }
      ]
    }
  ]
}